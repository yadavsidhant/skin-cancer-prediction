{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxSQA6wmok_Y"
      },
      "source": [
        "# SKIN CANCER PREDICTION WITH IMAGES USING HAM10000\n",
        "\n",
        "This tutorial is based on a self modified HAM10000 Dataset please modify the code according to your specific needs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnHWeAe0n3nj"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow tensorflowjs pandas matplotlib scikit-learn opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y4E5RN7nRqC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from google.colab import drive\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "K96IOhQyn5De",
        "outputId": "e81a13a9-b62d-4b21-b087-52c10520ee3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
            "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
            "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
            "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
            "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
            "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
            "\n",
            "        dataset                          image_path  \n",
            "0  vidir_modern  ./HAM10000_images/ISIC_0027419.jpg  \n",
            "1  vidir_modern  ./HAM10000_images/ISIC_0025030.jpg  \n",
            "2  vidir_modern  ./HAM10000_images/ISIC_0026769.jpg  \n",
            "3  vidir_modern  ./HAM10000_images/ISIC_0025661.jpg  \n",
            "4  vidir_modern  ./HAM10000_images/ISIC_0031633.jpg  \n",
            "         lesion_id      image_id   dx    dx_type   age     sex localization  \\\n",
            "0  HAMTEST_0000000  ISIC_0034524   nv  follow_up  40.0  female         back   \n",
            "1  HAMTEST_0000001  ISIC_0034525   nv      histo  70.0    male      abdomen   \n",
            "2  HAMTEST_0000002  ISIC_0034526  bkl      histo  70.0    male         back   \n",
            "3  HAMTEST_0000003  ISIC_0034527   nv      histo  35.0    male        trunk   \n",
            "4  HAMTEST_0000004  ISIC_0034528   nv  follow_up  75.0  female        trunk   \n",
            "\n",
            "         dataset                               image_path  \n",
            "0  vidir_molemax  ./ISIC2018_Test_Images/ISIC_0034524.jpg  \n",
            "1      rosendahl  ./ISIC2018_Test_Images/ISIC_0034525.jpg  \n",
            "2      rosendahl  ./ISIC2018_Test_Images/ISIC_0034526.jpg  \n",
            "3    vienna_dias  ./ISIC2018_Test_Images/ISIC_0034527.jpg  \n",
            "4  vidir_molemax  ./ISIC2018_Test_Images/ISIC_0034528.jpg  \n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "!unzip -q '/content/drive/MyDrive/HAM10000/HAM10000_images_part_1.zip' -d ./HAM10000_images\n",
        "!unzip -q '/content/drive/MyDrive/HAM10000/HAM10000_images_part_2.zip' -d ./HAM10000_images\n",
        "!unzip -q '/content/drive/MyDrive/HAM10000/ISIC2018_Task3_Test_Images.zip' -d ./ISIC2018_Test_Images\n",
        "\n",
        "metadata = pd.read_csv('/content/drive/MyDrive/HAM10000/HAM10000_metadata.csv')\n",
        "test_metadata = pd.read_csv('/content/drive/MyDrive/HAM10000/ISIC2018_Task3_Test_GroundTruth.csv')\n",
        "\n",
        "image_dir = './HAM10000_images'\n",
        "metadata['image_path'] = metadata['image_id'].apply(lambda x: os.path.join(image_dir, f'{x}.jpg'))\n",
        "\n",
        "test_image_dir = './ISIC2018_Test_Images'\n",
        "test_metadata['image_path'] = test_metadata['image_id'].apply(lambda x: os.path.join(test_image_dir, f'{x}.jpg'))\n",
        "\n",
        "print(metadata.head())\n",
        "print(test_metadata.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUoqKZl1n8SO"
      },
      "outputs": [],
      "source": [
        "!mv /content/HAM10000_images/HAM10000_images_part_1/* /content/HAM10000_images/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQWzdHCjoRKh"
      },
      "outputs": [],
      "source": [
        "!cat /content/HAM10000_images/Normal_Img_1.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g43yxtiYoZDW"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 128\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    rotation_range=20\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=metadata,\n",
        "    x_col='image_path',\n",
        "    y_col='dx',\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=metadata,\n",
        "    x_col='image_path',\n",
        "    y_col='dx',\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_metadata,\n",
        "    x_col='image_path',\n",
        "    y_col='dx',\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sxrwwka4ocma"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(8, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=14\n",
        ")\n",
        "\n",
        "model.save('skin_cancer_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zC2W6u6odW4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "class_indices = train_generator.class_indices\n",
        "with open('class_indices.json', 'w') as json_file:\n",
        "    json.dump(class_indices, json_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL1QBkKLofvG"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyGSfJ6jpZGn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import json\n",
        "from tensorflow.keras.preprocessing import image as keras_image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "IMAGE_SIZE = 128\n",
        "\n",
        "model = load_model('full_model.h5')\n",
        "\n",
        "with open('class_indices.json', 'r') as json_file:\n",
        "    class_indices = json.load(json_file)\n",
        "\n",
        "cancer_descriptions = {\n",
        "    'akiec': 'Actinic keratoses and intraepithelial carcinoma / Bowen\\'s disease',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'bkl': 'Benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses)',\n",
        "    'df': 'Dermatofibroma',\n",
        "    'mel': 'Melanoma',\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'vasc': 'Vascular lesions (angiomas, angiokeratomas, pyogenic granulomas, and hemorrhage)',\n",
        "    'healthy': 'This is healthy skin'\n",
        "}\n",
        "\n",
        "def generate_grid_image(image_array, grid_size=30):\n",
        "    grid = np.zeros((grid_size, grid_size))\n",
        "    image_shape = image_array.shape[:2]\n",
        "    step_x = image_shape[0] // grid_size\n",
        "    step_y = image_shape[1] // grid_size\n",
        "\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            grid[i, j] = np.mean(image_array[i*step_x:(i+1)*step_x, j*step_y:(j+1)*step_y])\n",
        "\n",
        "    return grid\n",
        "\n",
        "def generate_numerical_grid_image(image_array, threshold=0.5, grid_size=30):\n",
        "    grid = np.zeros((grid_size, grid_size))\n",
        "    image_shape = image_array.shape[:2]\n",
        "    step_x = image_shape[0] // grid_size\n",
        "    step_y = image_shape[1] // grid_size\n",
        "\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            mean_value = np.mean(image_array[i*step_x:(i+1)*step_x, j*step_y:(j+1)*step_y])\n",
        "            grid[i, j] = 1 if mean_value >= threshold else 0\n",
        "\n",
        "    return grid\n",
        "\n",
        "def generate_bounding_box(image_array, threshold=0.5):\n",
        "    img = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        confidence = 1 if np.mean(image_array[y:y+h, x:x+w]) >= threshold else 0\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255 * confidence, 0), 2)\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "def generate_confidence_grid(predictions, grid_size):\n",
        "    confidence_grid = np.zeros((grid_size, grid_size))\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            confidence_grid[i, j] = predictions[0, i * grid_size + j] if i * grid_size + j < predictions.shape[1] else 0\n",
        "    return confidence_grid\n",
        "\n",
        "def predict_cancer(image_path):\n",
        "    img = keras_image.load_img(image_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
        "    img_array = keras_image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_index = np.argmax(predictions, axis=1)[0]\n",
        "    predicted_label = list(class_indices.keys())[predicted_index]\n",
        "    confidence = predictions[0][predicted_index]\n",
        "\n",
        "    if predicted_label == 'healthy':\n",
        "        return predicted_label, confidence, None, None, None, None, img_array\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "\n",
        "    grid_image = generate_grid_image(img_array[0])\n",
        "    numerical_grid_image = generate_numerical_grid_image(img_array[0])\n",
        "    bounding_box_image = generate_bounding_box(img)\n",
        "    confidence_grid = generate_confidence_grid(predictions, grid_size=numerical_grid_image.shape[0])\n",
        "\n",
        "    return predicted_label, confidence, grid_image, numerical_grid_image, bounding_box_image, confidence_grid, img\n",
        "\n",
        "image_path = '/content/ISIC_0034065.jpg'\n",
        "predicted_label, confidence, grid_image, numerical_grid_image, bounding_box_image, confidence_grid, original_image_array = predict_cancer(image_path)\n",
        "\n",
        "print(f\"Predicted cancer type: {predicted_label}\")\n",
        "print(f\"Confidence: {confidence}\")\n",
        "if original_image_array is not None:\n",
        "    print(f\"Description: {cancer_descriptions[predicted_label]}\")\n",
        "\n",
        "    fig, axs = plt.subplots(1, 4, figsize=(20, 20))\n",
        "    axs[0].imshow(grid_image, cmap='hot', interpolation='nearest')\n",
        "    axs[0].set_title('30x30 Grid with Markings')\n",
        "    axs[1].imshow(numerical_grid_image, cmap='binary', interpolation='nearest')\n",
        "    axs[1].set_title('30x30 Grid Mask')\n",
        "    axs[2].imshow(cv2.cvtColor(original_image_array, cv2.COLOR_BGR2RGB))\n",
        "    axs[2].set_title('Original Image')\n",
        "    axs[3].imshow(bounding_box_image)\n",
        "    axs[3].set_title('Bounding Marking Area')\n",
        "\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}